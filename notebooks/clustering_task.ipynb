{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "import pandas as pd\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from copy import copy\n",
    "from tqdm.notebook import tqdm\n",
    "import nimfa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot clustering stats for nmf\n",
    "- Euclidean Distance\n",
    "- Kullback-leibler Distance\n",
    "- Number of iterations\n",
    "- Sparseness\n",
    "- Cophenetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clustering_stats_nmf(data, rank=(2,5), model='Bmf'):\n",
    "\n",
    "    # Vizz parameters\n",
    "    height = 20\n",
    "    width = 18\n",
    "    rank_min, rank_max = rank\n",
    "    # Trainig\n",
    "\n",
    "    model = nimfa.Bmf if model=='Bmf' else nimfa.Nmf\n",
    "    \n",
    "    results = model(data, \n",
    "                    seed=\"random\", \n",
    "                    rank=100, \n",
    "                    random_state=420,\n",
    "                    max_iter=100).estimate_rank(rank_range=range(rank_min, rank_max),\n",
    "                                                n_run=10,\n",
    "                                                what='all')\n",
    "\n",
    "    results = pd.DataFrame(results)\n",
    "    # Creating subplots\n",
    "    fig, axes = plt.subplots(nrows=5, \n",
    "                             ncols=1, \n",
    "                             figsize=(40,18), \n",
    "                             sharex=True)\n",
    "\n",
    "    fig_box, axes_box = plt.subplots(nrows=2, \n",
    "                                     ncols=1, \n",
    "                                     figsize=(25,18)\n",
    "#                                      , \n",
    "#                                      sharex=True\n",
    "                                    )\n",
    "    # Euclidean distance\n",
    "    results.loc['rss'].plot(figsize=(width,height),\n",
    "                            title='Distance - Euclidean',\n",
    "                            grid=True,\n",
    "                           ax=axes[0],\n",
    "                           lw=4)\n",
    "    # Kullback-Leibler distance\n",
    "    results.loc['kl'].plot(figsize=(width,height),\n",
    "                            title='Distance - Kullback-leibler',\n",
    "                            grid=True,\n",
    "                           ax=axes[1],\n",
    "                          lw=4)\n",
    "    # Iteration number in which the optimization stopped\n",
    "    results.loc['n_iter'].plot(figsize=(width,height),\n",
    "                        title='Number of iterations',\n",
    "                        grid=True,\n",
    "                           ax=axes[2],\n",
    "                              lw=4)\n",
    "    # Sparseness of the H and W matrices\n",
    "    spar = results.loc['sparseness'].values\n",
    "    pd.DataFrame(spar.tolist(),\n",
    "                 columns=['H','W'],\n",
    "                index=results.columns).plot(figsize=(width,height),\n",
    "                                            title='Sparseness',\n",
    "                                            grid=True,\n",
    "                                            ax=axes[3],\n",
    "                                           lw=4)\n",
    "    # Cophenetic score\n",
    "    results.loc['cophenetic'].plot(figsize=(width,height),\n",
    "                            title='Cophenetic',\n",
    "                            grid=True,\n",
    "                           ax=axes[4],\n",
    "                           lw=4)\n",
    "    # Predict features probabilities     \n",
    "    predict_features_prob = pd.DataFrame(dict(list(zip(results.loc['predict_features'].index, \n",
    "                                                 results.loc['predict_features'].map(lambda x: x[1]).values))))\n",
    "\n",
    "    predict_features_prob.boxplot(figsize=(width,height),\n",
    "    #                         title='predict features probabilities',\n",
    "                            grid=True,\n",
    "                            ax=axes_box[0])\n",
    "    # Predict samples probabilities\n",
    "    predict_samples_prob = pd.DataFrame(dict(list(zip(results.loc['predict_samples'].index, \n",
    "                                                 results.loc['predict_samples'].map(lambda x: x[1]).values))))\n",
    "\n",
    "    predict_samples_prob.boxplot(figsize=(width,height),\n",
    "    #                           title='predict samples probabilities',\n",
    "                              grid=True,\n",
    "                              ax=axes_box[1])\n",
    "    \n",
    "    plt.setp(axes, xticks=results.loc['predict_samples'].index)\n",
    "    plt.setp(axes_box, xticks=results.loc['predict_samples'].index)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silhouette_plot(X, y, n_clusters, ax=None):\n",
    "    from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "    # References: https://gist.github.com/clintval/e9afc246e77f6488cda79f86e4d37148\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    silhouette_avg = silhouette_score(X, y)\n",
    "    sample_silhouette_values = silhouette_samples(X, y)\n",
    "\n",
    "    y_lower = padding = 2\n",
    "    for i in range(n_clusters):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        ith_cluster_silhouette_values = sample_silhouette_values[y == i]\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.get_cmap(\"Spectral\")(float(i) / n_clusters)\n",
    "        ax.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                         0,\n",
    "                         ith_cluster_silhouette_values,\n",
    "                         facecolor=color,\n",
    "                         edgecolor=color,\n",
    "                         alpha=0.7)\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i + 1))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + padding\n",
    "\n",
    "    ax.set_xlabel(\"The silhouette coefficient values\")\n",
    "    title_label = 'Cluster label' if ax is None else f\"{n_clusters}-Clusters\"\n",
    "    ax.set_ylabel(f\"{title_label}\")\n",
    "\n",
    "    # The vertical line for average silhoutte score of all the values\n",
    "    ax.axvline(x=silhouette_avg, c='r', alpha=0.8, lw=0.8, ls='-')\n",
    "    ax.annotate('Average',\n",
    "                xytext=(silhouette_avg, y_lower * 1.025),\n",
    "                xy=(0, 0),\n",
    "                ha='center',\n",
    "                alpha=0.8,\n",
    "                c='r')\n",
    "\n",
    "    ax.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax.set_xticks([0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "    ax.set_ylim(0, y_upper + 1)\n",
    "    ax.set_xlim(-0.075, 1.0)\n",
    "    return ax"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Silhouette plot for KPrototypes algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KPrototypes_silhouette_plot(n_cluster, modelled, ax=None):\n",
    "    kp = KPrototypes(random_state=420, \n",
    "                    n_jobs=-1, \n",
    "                    init='Huang',\n",
    "                    n_init=10,\n",
    "                    n_clusters=n_cluster)\n",
    "\n",
    "    kp.fit(modelled, categorical=[i for i, x in enumerate(modelled.columns[:-3])])\n",
    "\n",
    "    predicted = kp.predict(modelled, categorical=[i for i, x in enumerate(modelled.columns[:-3])])\n",
    "\n",
    "    silhouette_plot(modelled, predicted, len(pd.unique(predicted)), ax=ax)\n",
    "    \n",
    "#     plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Davies-Bouldin Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def davies_bouldin_plot(model, data, cluster_tuple):\n",
    "    \n",
    "    initial, final = cluster_tuple\n",
    "    \n",
    "    n_clusters = []\n",
    "    db_score = []\n",
    "\n",
    "    for k in tqdm(range(initial, final)):\n",
    "        km = copy(model)\n",
    "        km.set_params(n_clusters=k)\n",
    "        predicted = km.fit_predict(data)\n",
    "\n",
    "        n_clusters.append(k)\n",
    "        \n",
    "        db_score.append(davies_bouldin_score(data, predicted))\n",
    "        \n",
    "    return pd.DataFrame({'n_clusters':n_clusters,\n",
    "                        'davies_bouldin_score':db_score})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualização da distância de entre os grupos\n",
    "- Nos gráficos abaixo, são representados as distâncias entre os grupos de um método de agrupamento.\n",
    "- O tamanho do círculo representa a proporção dos elementos na base que pertencem aos grupos.\n",
    "- A distância entre os centróides dos círculos, representa a distância entre os centróides dos grupos.\n",
    "- A sobreposição dos grupos não necessariamente signifca que eles se sobrepõe no espaço original, é apenas uma representação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.cluster import InterclusterDistance\n",
    "\n",
    "# Instantiate the clustering model and visualizer\n",
    "model = KMeans(9,\n",
    "               random_state=420,\n",
    "               n_jobs=-1)\n",
    "visualizer_intercluster = InterclusterDistance(model, random_state=420)\n",
    "\n",
    "visualizer_intercluster.fit(modelled)        # Fit the data to the visualizer\n",
    "visualizer_intercluster.show()        # Finalize and render the figure"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Método da silhouetta\n",
    "- Essa métrica busca definir quão compacto e pouco disperso os elementos do grupo são, sendo os valores entre 1 e -1, sendo 1 o mais definido e -1 o menos definido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.cluster import SilhouetteVisualizer\n",
    "\n",
    "# Instantiate the clustering model and visualizer\n",
    "model = KMeans(9, random_state=420, n_jobs=-1)\n",
    "visualizer_four = SilhouetteVisualizer(model, colors='yellowbrick')\n",
    "    \n",
    "visualizer_four.fit(modelled)        # Fit the data to the visualizer\n",
    "visualizer_four.show()        # Finalize and render the figure"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Método do cotovelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from sklearn.cluster import KMeans\n",
    "    \n",
    "# Instantiate the clustering model and visualizer\n",
    "model = KMeans(random_state=420)\n",
    "visualizer_silhouette = KElbowVisualizer(model, k=(2,20), metric='silhouette')\n",
    "\n",
    "visualizer_silhouette.fit(modelled)        # Fit the data to the visualizer\n",
    "# visualizer_silhouette.fit(sample)        # Fit the data to the visualizer\n",
    "visualizer_silhouette.show()        # Finalize and render the figure"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Método de Calinski Harabasz\n",
    "- Essa métrica, define uma proporção entre a dispersão do agrupamento com o próprio grupo e a dispersão entre os grupos, onde a dispersão é definida como a soma das distâncias ao quadrado.\n",
    "- Para essa métrica, é definido que quanto maior o valor, mais bem definidos os clusters estão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# The score is defined as ratio between the within-cluster dispersion and the between-cluster dispersion.\n",
    "# The index is the ratio of the sum of between-clusters dispersion and of inter-cluster \n",
    "# dispersion for all clusters (where dispersion is defined as the sum of distances squared)\n",
    "# also known as the Variance Ratio Criterion - can be used to evaluate the model, where a higher \n",
    "# Calinski-Harabasz score relates to a model with better defined clusters.\n",
    "    \n",
    "    \n",
    "# Instantiate the clustering model and visualizer\n",
    "model = KMeans(random_state=420)\n",
    "visualizer_calinski_harabasz = KElbowVisualizer(model, k=(2,20), metric='calinski_harabasz')\n",
    "\n",
    "visualizer_calinski_harabasz.fit(modelled)        # Fit the data to the visualizer\n",
    "visualizer_calinski_harabasz.show()               # Finalize and render the figure"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scora-monitor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
